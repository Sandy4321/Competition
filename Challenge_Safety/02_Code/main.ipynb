{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For reading data filenames \n",
    "import glob\n",
    "\n",
    "\n",
    "# For calculating Time \n",
    "import datetime\n",
    "\n",
    "\n",
    "# For processing data\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For Features Creation\n",
    "from feature_engineering import *\n",
    "\n",
    "## For Model Building\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "## For Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "## For Sequence Model\n",
    "from sklearn.utils import class_weight\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "## For Plotting Graphs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "## For ignoring Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path of data sets\n",
    "train_path = '../01_Data/Train/*.csv'\n",
    "test_path = '../01_Data/Validation/*.csv'\n",
    "labels_path = '../01_Data/labels/part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv'\n",
    "output_path = '../03_Results/test_pred1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data and sorted the data at boookingID*second level\n",
    "\n",
    "def data_load_fun(train_path):\n",
    "    start = datetime.datetime.now().replace(microsecond=0)\n",
    "    features = pd.DataFrame()\n",
    "    filename = []\n",
    "    for files in glob.glob(train_path):\n",
    "        filename.append(files)\n",
    "    for file in filename:\n",
    "        print (file)\n",
    "        tmp_df = pd.read_csv(file)\n",
    "        features = pd.concat([features,tmp_df], axis=0)\n",
    "    features = features.sort_values(by= ['bookingID',\"second\"])\n",
    "    end = datetime.datetime.now().replace(microsecond=0)\n",
    "    print (len(filename), \" Files Loaded Successfuly; Time Taken -->\" ,end-start)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_processing(df):\n",
    "    df = df[df.second <10000]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features Creation\n",
    "def features_creation(features,labels,train_ind=False):\n",
    "    start = datetime.datetime.now().replace(microsecond=0)\n",
    "    \n",
    "    features = generic_features_creation_01(features)\n",
    "    \n",
    "    windows_feas1 = window_features_creation1_03(features,window_size=10,over_wd=5,\n",
    "                                   cols =['Accuracy','Bearing','Speed','gyro','acceleration','acc_cal'])\n",
    "    windows_feas2 = window_features_creation1_03(features,window_size=10,over_wd=5,\n",
    "                                   cols =['signal_weak','stop','trip_start','missing_ind','trip_end'], \n",
    "                                    metrics = {\"sum\",\"max\"})\n",
    "    window_feas_final = pd.merge(windows_feas1, windows_feas2, on= ['bookingID','window'], how = \"left\")\n",
    "    end = datetime.datetime.now().replace(microsecond=0)\n",
    "    print (window_feas_final.shape[1], \" Features Created at sliding waindow of 10s with overlap of 5s; Time Taken->\", end-start)\n",
    "    \n",
    "    fset1 = generic_trip_features_02(features)\n",
    "    fset2 = window_grp_stop_04(window_feas_final)\n",
    "    fset3 = window_grp_speed_05(window_feas_final)\n",
    "    fset4 = window_grp_bearing_06(window_feas_final, cols = ['Bearing_std',\"Bearing_max\",\"Bearing_min\"], thres=10, var_nm=\"turn\")\n",
    "    fset5 = trip_ending_fes_07(window_feas_final)\n",
    "    fset6 = window_grp_accuracy_08(window_feas_final)\n",
    "    fset7 = generic_stats_features_09(window_feas_final, cols= [\"Speed\",\"acc_cal\",\"Accuracy\",\"acceleration\",\"gyro\"])\n",
    "    fset8 = events_calculation_10(window_feas_final)\n",
    "\n",
    "    fset=fset1.copy()\n",
    "    fset = fset.merge(fset2, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset3, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset4, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset5, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset6, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset7, on = ['bookingID'], how = \"left\")\n",
    "    fset = fset.merge(fset8, on = ['bookingID'], how = \"left\")\n",
    "    \n",
    "    end1 = datetime.datetime.now().replace(microsecond=0)\n",
    "    print (fset.shape[1], \" Features Created from windows data; Time taken ->\", end1- end)\n",
    "    \n",
    "    lstm_fset,lstm_y,bids = lstm_features_12(window_feas_final, labels,train_ind=train_ind)\n",
    "    end2 = datetime.datetime.now().replace(microsecond=0)\n",
    "    print (lstm_fset.shape, \" LSTM Features Created Done; Time taken ->\", end2- end1)\n",
    "    return fset,lstm_fset,lstm_y,bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_full_processing(path,labels,train_ind=False):\n",
    "    data = data_load_fun(path)\n",
    "    data = data_pre_processing(data)\n",
    "    features,lstm_features,lstm_y,lstm_bids = features_creation(data,labels,train_ind=train_ind)\n",
    "    return features,lstm_features,lstm_y,lstm_bids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read Labels and Incase keep the positive value \n",
    "labels = pd.read_csv(labels_path)\n",
    "labels = labels.groupby(['bookingID']).max().reset_index()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../01_Data/Train/part-00001-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "../01_Data/Train/part-00007-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "../01_Data/Train/part-00002-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "train_features,train_lstm_features,train_lstm_y,train_lstm_bids = data_full_processing(train_path,labels,train_ind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_lstm_y),\n",
    "                                                 train_lstm_y)\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=8, return_sequences= True, input_shape=(train_lstm_features.shape[1],\n",
    "                                                                  train_lstm_features.shape[2])))\n",
    "model_lstm.add(LSTM(units=5))\n",
    "model_lstm.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(train_lstm_features, train_lstm_y, epochs=20, batch_size=256, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_score = pd.DataFrame()\n",
    "lstm_score['bookingID'] = train_lstm_bids\n",
    "lstm_score['lstm_score'] = model_lstm.predict_proba(train_lstm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.merge(train_features, labels, on= ['bookingID'], how=\"left\")\n",
    "train_features = pd.merge(train_features, lstm_score, on= ['bookingID'], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['bookingID','label']\n",
    "train_target = train_features[['bookingID','label']]\n",
    "train_features = train_features.drop(columns = drop_cols, axis=1)\n",
    "train_features.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_leaves': 8, 'colsample_bytree': 0.7414265939570617, 'max_depth': 6, \n",
    "               'learning_rate': 0.019922131503094735, 'subsample': 0.5675422486112608,\n",
    " 'min_data_in_leaf': 51, 'min_sum_hessian_in_leaf': 10, 'bagging_freq': 9, \"scale_pos_weight\": (1 - np.mean(train_target.label))/np.mean(train_target.label)}\n",
    "\n",
    "model = lgb.LGBMClassifier(**best_params, n_estimators = 200, nthread = 4, n_jobs = -1)\n",
    "model.fit(train_features, train_target.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict_proba(train_features)[:,1]\n",
    "\n",
    "print (\"stats--->\")\n",
    "print (\"\")\n",
    "#y_train_pred = len*[0]\n",
    "\n",
    "\n",
    "fpr_train, tpr_train, thresholds = roc_curve(train_target.label,train_pred)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "print (\"Train ROC --> \", roc_auc_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color='darkorange', lw=2, label='Train ROC curve (area = %0.2f)' % roc_auc_train)\n",
    "#plt.plot(fpr_val, tpr_val, color='red', lw=2, label='Val ROC curve (area = %0.2f)' % roc_auc_val)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features,test_lstm_features,test_lstm_y,test_lstm_bids = data_full_processing(test_path,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm_score = pd.DataFrame()\n",
    "test_lstm_score['bookingID'] = test_lstm_bids\n",
    "test_lstm_score['lstm_score'] = model_lstm.predict_proba(test_lstm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.merge(test_features, test_lstm_score, on= ['bookingID'], how=\"left\")\n",
    "drop_cols = ['bookingID']\n",
    "test_target = test_features[['bookingID']]\n",
    "test_features = test_features.drop(columns = drop_cols, axis=1)\n",
    "test_features.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target['score'] = model.predict_proba(test_features)[:,1]\n",
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.to_csv(output_path,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
